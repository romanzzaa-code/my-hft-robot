# hft_strategy/pipelines/export_data.py
import asyncio
import asyncpg
import numpy as np
import logging
import orjson
import os
import argparse
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å —Å–æ—Å–µ–¥–Ω–∏–µ –º–æ–¥—É–ª–∏
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import DB_CONFIG
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à SSOT
from domain.events import (
    DEPTH_EVENT, TRADE_EVENT, DEPTH_CLEAR_EVENT, DEPTH_SNAPSHOT_EVENT,
    BUY_EVENT, SELL_EVENT, EXCH_EVENT, LOCAL_EVENT
)

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("PIPELINE")

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –∂–µ—Å—Ç–∫–æ —Ç—Ä–µ–±—É–µ–º–∞—è hftbacktest (Rust)
RUST_DTYPE = np.dtype([
    ('ev', 'uint64'),       
    ('exch_ts', 'int64'),   
    ('local_ts', 'int64'),  
    ('px', 'float64'),      
    ('qty', 'float64'),     
    ('order_id', 'uint64'), 
    ('ival', 'int64'),      
    ('fval', 'float64')     
])

async def export_data(symbol: str, output_file: str, days: int = 30):
    logger.info(f"üöÄ Starting EXPORT for {symbol} -> {output_file}")
    
    conn = await asyncpg.connect(**DB_CONFIG.as_dict())
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π (list of tuples –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º append –≤ numpy)
    raw_events = []
    
    try:
        first_snapshot_ts = None
        
        async with conn.transaction():
            # ==================================================================
            # –≠–¢–ê–ü 1: –°–¢–ê–ö–ê–ù–´ (SNAPSHOTS & DELTAS)
            # ==================================================================
            logger.info("üìö Phase 1: Streaming Order Book Data...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–π –∫—É—Ä—Å–æ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            query_depth = f"""
                SELECT 
                    EXTRACT(EPOCH FROM exch_time) * 1000000000 AS exch_ts, 
                    EXTRACT(EPOCH FROM time) * 1000000000 AS local_ts,
                    bids,
                    asks,
                    is_snapshot
                FROM market_depth_snapshots
                WHERE symbol = '{symbol}' 
                  AND time > NOW() - INTERVAL '{days} days'
                ORDER BY time ASC
            """
            
            async for row in conn.cursor(query_depth):
                # –ü—Ä–∏–≤–æ–¥–∏–º –∫ int
                ts_exch = int(row['exch_ts'])
                ts_local = int(row['local_ts'])
                is_snapshot = row['is_snapshot']

                # –ò—â–µ–º "—è–∫–æ—Ä—å" - –ø–µ—Ä–≤—ã–π —Å–Ω—ç–ø—à–æ—Ç, —Å –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—á–Ω–µ–º –∏—Å—Ç–æ—Ä–∏—é
                if first_snapshot_ts is None:
                    if not is_snapshot:
                        continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ–ª—å—Ç—ã –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Å–Ω–∏–º–∫–∞
                    first_snapshot_ts = ts_local
                    logger.info(f"‚ú® Anchor SNAPSHOT found at {first_snapshot_ts}")

                # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è JSONB (orjson –±—ã—Å—Ç—Ä–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ json)
                # asyncpg –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å str –∏–ª–∏ —É–∂–µ bytes
                bids = orjson.loads(row['bids']) if isinstance(row['bids'], (str, bytes)) else row['bids']
                asks = orjson.loads(row['asks']) if isinstance(row['asks'], (str, bytes)) else row['asks']
                
                # –ë–∞–∑–æ–≤—ã–µ —Ñ–ª–∞–≥–∏ –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞–∫–µ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
                # –î–æ–±–∞–≤–ª—è–µ–º EXCH –∏ LOCAL, —á—Ç–æ–±—ã –¥–≤–∏–∂–æ–∫ Rust –Ω–µ –æ—Ç–±—Ä–æ—Å–∏–ª –∏—Ö
                base_flags = EXCH_EVENT | LOCAL_EVENT

                if is_snapshot:
                    # –°–æ–±—ã—Ç–∏–µ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞–∫–∞–Ω–∞ –ø–µ—Ä–µ–¥ –Ω–∞–∫–∞—Ç–∫–æ–π —Å–Ω–∞–ø—à–æ—Ç–∞
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–≤–∏–∂–∫–∞ —Ç—Ä–µ–±—É—é—Ç SNAPSHOT —Ñ–ª–∞–≥ –≤–º–µ—Å—Ç–æ CLEAR, 
                    # –Ω–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥: Clear -> Add Orders
                    raw_events.append((
                        base_flags | DEPTH_CLEAR_EVENT, 
                        ts_exch, ts_local, 0.0, 0.0, 0, 0, 0.0
                    ))
                    # –î–ª—è —Å–æ–±—ã—Ç–∏–π –≤–Ω—É—Ç—Ä–∏ —Å–Ω–∞–ø—à–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º DEPTH_SNAPSHOT_EVENT
                    type_flag = DEPTH_SNAPSHOT_EVENT
                else:
                    # –î–ª—è –¥–µ–ª—å—Ç
                    type_flag = DEPTH_EVENT

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ Bids
                if bids:
                    for p, q in bids:
                        # –§–ª–∞–≥ = Base | Type | Side
                        flag = base_flags | type_flag | BUY_EVENT
                        raw_events.append((
                            flag, ts_exch, ts_local, float(p), float(q), 0, 0, 0.0
                        ))
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ Asks
                if asks:
                    for p, q in asks:
                        # –í HftBacktest Side —á–∞—Å—Ç–æ –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è —Ñ–ª–∞–≥–æ–º, –Ω–æ –∏–Ω–æ–≥–¥–∞ —Ç—Ä–µ–±—É—é—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–º
                        # –î–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –¥–µ–ª–∞–µ–º –∏ —Ñ–ª–∞–≥, –∏ –∑–Ω–∞–∫ (–µ—Å–ª–∏ –≤–µ—Ä—Å–∏—è –¥–≤–∏–∂–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–Ω–∞–∫)
                        flag = base_flags | type_flag | SELL_EVENT
                        # qty –±–µ—Ä–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (legacy support), 
                        # —Ö–æ—Ç—è —Ñ–ª–∞–≥ SELL_EVENT –≥–ª–∞–≤–Ω–µ–µ.
                        raw_events.append((
                            flag, ts_exch, ts_local, float(p), -float(q), 0, 0, 0.0
                        ))

            if first_snapshot_ts is None:
                logger.error("‚ùå No snapshot found! Cannot build order book.")
                return

            # ==================================================================
            # –≠–¢–ê–ü 2: –°–î–ï–õ–ö–ò (TRADES)
            # ==================================================================
            logger.info("üìä Phase 2: Streaming Trades...")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º start_time –æ–±—Ä–∞—Ç–Ω–æ –≤ timestamp –¥–ª—è SQL
            start_time_sql = first_snapshot_ts / 1_000_000_000.0
            
            query_trades = f"""
                SELECT 
                    EXTRACT(EPOCH FROM exch_time) * 1000000000 AS exch_ts, 
                    EXTRACT(EPOCH FROM time) * 1000000000 AS local_ts,
                    price,
                    volume,
                    is_buyer_maker
                FROM market_ticks
                WHERE symbol = '{symbol}' 
                  AND time >= to_timestamp({start_time_sql})
            """
            
            async for row in conn.cursor(query_trades):
                # is_buyer_maker=True -> –ü—Ä–æ–¥–∞–≤–µ—Ü –±—ã–ª –∏–Ω–∏—Ü–∏–∞—Ç–æ—Ä–æ–º (Sell Aggressor)
                is_sell = row['is_buyer_maker']
                
                base_flags = EXCH_EVENT | LOCAL_EVENT | TRADE_EVENT
                
                if is_sell:
                    flag = base_flags | SELL_EVENT
                    qty = -float(row['volume'])
                else:
                    flag = base_flags | BUY_EVENT
                    qty = float(row['volume'])
                
                raw_events.append((
                    flag,
                    int(row['exch_ts']),
                    int(row['local_ts']),
                    float(row['price']),
                    qty,
                    0, 0, 0.0
                ))

        # ==================================================================
        # –≠–¢–ê–ü 3: –°–ë–û–†–ö–ê –ò –°–û–•–†–ê–ù–ï–ù–ò–ï
        # ==================================================================
        logger.info(f"üî® Merging {len(raw_events)} events...")
        
        # –°–æ–∑–¥–∞–µ–º numpy array —Å –∂–µ—Å—Ç–∫–∏–º dtype
        data_np = np.array(raw_events, dtype=RUST_DTYPE)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏ (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –¥–≤–∏–∂–∫–∞)
        logger.info("Sorting by local_ts...")
        data_np.sort(order=['local_ts'], kind='stable')
        
        # Memory Alignment (–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è Rust FFI)
        data_np = np.ascontiguousarray(data_np)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ (Negative Latency Patch)
        # –ï—Å–ª–∏ local < exch, –¥–≤–∏–≥–∞–µ–º local –≤–ø–µ—Ä–µ–¥
        mask = data_np['local_ts'] < data_np['exch_ts']
        if np.any(mask):
            count = np.count_nonzero(mask)
            logger.warning(f"ü©π Fixing {count} negative latency timestamps...")
            data_np['local_ts'][mask] = data_np['exch_ts'][mask]

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω–µ—Ç
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        logger.info(f"üíæ Saving compressed NPZ to {output_file}...")
        np.savez_compressed(output_file, data=data_np)
        
        logger.info("‚úÖ EXPORT COMPLETE.")

    except Exception as e:
        logger.error(f"‚ùå Export Failed: {e}", exc_info=True)
    finally:
        await conn.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Export HFT Data from TimescaleDB")
    parser.add_argument("--symbol", type=str, required=True, help="Trading Pair (e.g. SOLUSDT)")
    parser.add_argument("--output", type=str, default=None, help="Output path")
    parser.add_argument("--days", type=int, default=30, help="Days to export")
    
    args = parser.parse_args()
    
    if args.output is None:
        args.output = f"data/{args.symbol}_v2.npz"
        
    # Windows Patch
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        
    asyncio.run(export_data(args.symbol, args.output, args.days))